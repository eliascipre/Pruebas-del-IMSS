# üìã An√°lisis Detallado del Proceso de Inicio - Suite IMSS

## üéØ Resumen Ejecutivo

El script `start-all.sh` es un sistema unificado que inicia **6 servicios** de la Suite IMSS de forma coordinada:

1. **Chatbot** (Puerto 5001) - FastAPI backend con LangChain y vLLM/Ollama
2. **Educaci√≥n** (Puerto 5002) - Flask app para educaci√≥n en radiograf√≠as
3. **Simulaci√≥n** (Puerto 5003) - Flask app para simulaci√≥n de entrevistas m√©dicas
4. **Radiograf√≠as** (Puerto 5004) - Flask app con RAG para an√°lisis de radiograf√≠as
5. **NV-Reason-CXR** (Puerto 5005) - Gradio service para an√°lisis de radiograf√≠as con NVIDIA
6. **Gateway** (Puerto 3001) - Next.js frontend que act√∫a como gateway unificado

---

## üèóÔ∏è Arquitectura del Sistema

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Gateway (Next.js)                         ‚îÇ
‚îÇ                    Puerto: 3001                             ‚îÇ
‚îÇ                    http://localhost:3001                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚îú‚îÄ‚îÄ‚îÄ‚ñ∫ Chatbot (FastAPI) - Puerto 5001
               ‚îú‚îÄ‚îÄ‚îÄ‚ñ∫ Educaci√≥n (Flask) - Puerto 5002
               ‚îú‚îÄ‚îÄ‚îÄ‚ñ∫ Simulaci√≥n (Flask) - Puerto 5003
               ‚îú‚îÄ‚îÄ‚îÄ‚ñ∫ Radiograf√≠as (Flask) - Puerto 5004
               ‚îî‚îÄ‚îÄ‚îÄ‚ñ∫ NV-Reason-CXR (Gradio) - Puerto 5005
```

---

## üì¶ Servicios Detallados

### 1. **Chatbot** (Puerto 5001)

**Tecnolog√≠a:** FastAPI (Python)
**Archivo principal:** `chatbot/main.py`
**Comando de inicio:**
```bash
cd chatbot && source ../venv/bin/activate && python3 main.py
```

**Caracter√≠sticas:**
- Backend as√≠ncrono con FastAPI
- Integraci√≥n con LangChain para gesti√≥n de conversaciones
- Soporte para vLLM (MedGemma 27B) para texto
- Soporte para Ollama (MedGemma 4B) para im√°genes
- Sistema de memoria conversacional con SQLite
- Almacenamiento de medios (im√°genes, audio, video)
- Transcripci√≥n de audio con Whisper
- An√°lisis m√©dico de im√°genes con Ollama
- Streaming de respuestas
- Sistema de cancelaci√≥n de requests

**Endpoints principales:**
- `POST /api/chat` - Chat con streaming
- `POST /api/chat/image` - Chat con im√°genes
- `POST /api/chat/audio` - Chat con audio
- `GET /health` - Health check
- `POST /api/cancel` - Cancelar request activo

**Dependencias:**
- Python 3.x
- FastAPI, uvicorn
- LangChain, langchain-openai
- httpx (para Ollama)
- SQLite (para memoria)
- Whisper (para transcripci√≥n)

**Variables de entorno:**
- `VLLM_ENDPOINT` - Endpoint de vLLM (default: http://localhost:8000/v1/)
- `OLLAMA_ENDPOINT` - Endpoint de Ollama (default: http://localhost:11434)
- `OLLAMA_IMAGE_MODEL` - Modelo de Ollama para im√°genes (default: amsaravi/medgemma-4b-it:q8)

---

### 2. **Educaci√≥n** (Puerto 5002)

**Tecnolog√≠a:** Flask (Python)
**Archivo principal:** `Educacion_radiografia/app.py`
**Comando de inicio:**
```bash
cd Educacion_radiografia && python3 app.py
```

**Caracter√≠sticas:**
- Aplicaci√≥n Flask para educaci√≥n en radiograf√≠as
- Sistema de cach√© para respuestas
- Cliente LLM local (MedGemma)
- Interfaz web con templates HTML
- Generaci√≥n de reportes educativos

**Endpoints principales:**
- `GET /api/health` - Health check
- `POST /api/analyze` - An√°lisis de radiograf√≠a
- `GET /` - Interfaz web principal

**Dependencias:**
- Python 3.x
- Flask, flask-cors
- Cliente LLM local

---

### 3. **Simulaci√≥n** (Puerto 5003)

**Tecnolog√≠a:** Flask (Python) + React (Frontend)
**Archivo principal:** `Simulacion/app.py`
**Comando de inicio:**
```bash
cd Simulacion && python3 app.py
```

**Caracter√≠sticas:**
- Simulador de entrevistas m√©dicas
- Frontend React compilado
- Integraci√≥n con Gemini TTS para voz
- Sistema de evaluaci√≥n de reportes
- Cach√© de conversaciones
- Simulaci√≥n de pacientes con condiciones m√©dicas

**Endpoints principales:**
- `GET /api/health` - Health check
- `GET /api/stream_conversation` - Streaming de conversaci√≥n
- `GET /api/evaluate` - Evaluaci√≥n de reporte
- `GET /` - Interfaz web principal

**Dependencias:**
- Python 3.x
- Flask, flask-cors
- Gemini TTS
- Cliente LLM local (MedGemma/Gemini)

---

### 4. **Radiograf√≠as** (Puerto 5004)

**Tecnolog√≠a:** Flask (Python) + React (Frontend)
**Archivo principal:** `radiografias_torax/backend/app.py`
**Comando de inicio:**
```bash
cd radiografias_torax/backend && source ../../venv/bin/activate && FORCE_CPU=1 python3 app.py
```

**Caracter√≠sticas:**
- Sistema RAG (Retrieval-Augmented Generation) para radiograf√≠as
- Base de conocimiento con ChromaDB
- Embeddings con SigLIP
- An√°lisis de radiograf√≠as de t√≥rax
- Frontend React con Vite
- Sistema de cach√© persistente
- Gesti√≥n de casos m√©dicos

**Endpoints principales:**
- `GET /api/health` - Health check
- `POST /api/analyze` - An√°lisis de radiograf√≠a
- `GET /api/cases` - Lista de casos
- `GET /` - Interfaz web principal

**Dependencias:**
- Python 3.x
- Flask, flask-cors
- ChromaDB (para RAG)
- SigLIP (para embeddings)
- Cliente LLM local (MedGemma)

**Variables de entorno:**
- `FORCE_CPU=1` - Forzar uso de CPU (evita problemas de VRAM)

---

### 5. **NV-Reason-CXR** (Puerto 5005)

**Tecnolog√≠a:** Gradio (Python)
**Archivo principal:** `nv-reason-cxr/app.py`
**Script de inicio:** `nv-reason-cxr/run_local.sh`
**Comando de inicio:**
```bash
cd nv-reason-cxr && source ../venv/bin/activate && PORT=5005 FORCE_CPU=1 NV_REASON_ALLOW_DOWNLOADS=0 bash run_local.sh --skip-venv
```

**Caracter√≠sticas:**
- Servicio Gradio para an√°lisis de radiograf√≠as
- Modelo NVIDIA NV-Reason-CXR-3B
- Interfaz web interactiva con Gradio
- Soporte para modo offline (sin descargas)
- Detecci√≥n autom√°tica de modelo local

**Endpoints principales:**
- `GET /` - Interfaz web Gradio
- API de Gradio para an√°lisis de im√°genes

**Dependencias:**
- Python 3.x
- Gradio
- Transformers, torch
- Modelo NV-Reason-CXR-3B

**Variables de entorno:**
- `PORT` - Puerto HTTP (default: 5005)
- `FORCE_CPU=1` - Forzar uso de CPU
- `NV_REASON_ALLOW_DOWNLOADS` - Permitir descargas (0=offline, 1=online)
- `NV_REASON_MODEL_PATH` - Ruta al modelo local
- `MODEL` - Nombre del modelo (default: nvidia/NV-Reason-CXR-3B)

**Resoluci√≥n de modelo:**
1. Busca en `NV_REASON_MODEL_PATH` (si est√° definido)
2. Busca en `~/.cache/huggingface/hub/models--nvidia--NV-Reason-CXR-3B`
3. Si no encuentra, permite descarga (si `NV_REASON_ALLOW_DOWNLOADS=1`)

---

### 6. **Gateway** (Puerto 3001)

**Tecnolog√≠a:** Next.js (TypeScript/React)
**Archivo principal:** `UI_IMSS/package.json` (npm run dev)
**Comando de inicio:**
```bash
cd UI_IMSS && HOSTNAME=0.0.0.0 SERVICIO_CHATBOT_URL=http://[LOCAL_IP]:5001 SERVICIO_EDUCACION_URL=http://[LOCAL_IP]:5002 SERVICIO_SIMULACION_URL=http://[LOCAL_IP]:5003 SERVICIO_RADIOGRAFIAS_URL=http://[LOCAL_IP]:5004 npm run dev
```

**Caracter√≠sticas:**
- Frontend unificado con Next.js 16
- Gateway que conecta todos los servicios backend
- Interfaz de usuario moderna con Tailwind CSS
- Sistema de autenticaci√≥n
- P√°ginas: Chat, Educaci√≥n, Simulaci√≥n, Radiograf√≠as, DICOM, etc.
- Modo oscuro/claro
- Responsive design

**P√°ginas principales:**
- `/` - P√°gina de inicio
- `/chat` - Chat m√©dico con IA
- `/home` - Dashboard principal
- `/login` - Autenticaci√≥n
- `/radiografias` - An√°lisis de radiograf√≠as
- `/dicom` - Visor DICOM
- `/dicom-ohif` - Visor DICOM con OHIF

**Dependencias:**
- Node.js, npm
- Next.js 16
- React 19
- Tailwind CSS
- TypeScript

**Variables de entorno:**
- `HOSTNAME=0.0.0.0` - Escuchar en todas las interfaces
- `SERVICIO_CHATBOT_URL` - URL del servicio Chatbot
- `SERVICIO_EDUCACION_URL` - URL del servicio Educaci√≥n
- `SERVICIO_SIMULACION_URL` - URL del servicio Simulaci√≥n
- `SERVICIO_RADIOGRAFIAS_URL` - URL del servicio Radiograf√≠as

---

## üîÑ Flujo de Inicio del Script

### Fase 1: Preparaci√≥n
1. **Verificaci√≥n de dependencias:**
   - Python 3.x
   - Node.js
   - npm

2. **Limpieza de procesos anteriores:**
   - Mata procesos en puertos 3000, 3001, 5001-5005
   - Limpia archivos PID en `logs/`

3. **Detecci√≥n de IP local:**
   - Linux: `ip route get 1.1.1.1`
   - macOS: `route get default`
   - Fallback: `192.168.1.26`

4. **Creaci√≥n de directorio de logs:**
   - Crea `logs/` si no existe

### Fase 2: Inicio de Servicios Backend

**Orden de inicio:**
1. **Chatbot** (5001) - Primero porque es el m√°s cr√≠tico
2. **Educaci√≥n** (5002)
3. **Simulaci√≥n** (5003)
4. **Radiograf√≠as** (5004)
5. **NV-Reason-CXR** (5005)

**Proceso para cada servicio:**
1. Verifica si existe `venv/`
2. Si existe, activa el venv
3. Ejecuta el comando en background con `nohup`
4. Guarda PID en `logs/[servicio].pid`
5. Redirige stdout/stderr a `logs/[servicio].log`

**Espera inicial:**
- Espera 8 segundos despu√©s de iniciar todos los backends

### Fase 3: Inicio del Gateway

1. **Inicia Gateway Next.js:**
   - Configura variables de entorno con IPs locales
   - Ejecuta `npm run dev` en background
   - Guarda PID en `logs/gateway.pid`

2. **Espera adicional:**
   - Espera 5 segundos para que el gateway se inicie

### Fase 4: Verificaci√≥n de Servicios

**Health checks (en paralelo, no bloqueantes):**
- `http://localhost:5001/health` - Chatbot
- `http://localhost:5002/api/health` - Educaci√≥n
- `http://localhost:5003/api/health` - Simulaci√≥n
- `http://localhost:5004/api/health` - Radiograf√≠as
- `http://localhost:5005` - NV-Reason-CXR

**Detecci√≥n de puerto del Gateway:**
- Busca en puertos 3001, 3000, 3002, 3003
- Verifica con `ss` o `check_port`
- Si no encuentra, usa 3001 como default

### Fase 5: Monitoreo Continuo

**Loop de monitoreo:**
- Cada 60 segundos verifica que todos los servicios est√©n activos
- Si alg√∫n servicio se cae, muestra advertencia
- Muestra estado actualizado

**Manejo de se√±ales:**
- `Ctrl+C` (SIGINT) ‚Üí Limpia todos los servicios y sale
- `SIGTERM` ‚Üí Limpia todos los servicios y sale

---

## üìä Gesti√≥n de Logs

**Estructura de logs:**
```
logs/
‚îú‚îÄ‚îÄ chatbot.log
‚îú‚îÄ‚îÄ educacion.log
‚îú‚îÄ‚îÄ simulacion.log
‚îú‚îÄ‚îÄ radiografias.log
‚îú‚îÄ‚îÄ nv-reason-cxr.log
‚îú‚îÄ‚îÄ gateway.log
‚îú‚îÄ‚îÄ chatbot.pid
‚îú‚îÄ‚îÄ educacion.pid
‚îú‚îÄ‚îÄ simulacion.pid
‚îú‚îÄ‚îÄ radiografias.pid
‚îú‚îÄ‚îÄ nv-reason-cxr.pid
‚îî‚îÄ‚îÄ gateway.pid
```

**Ver logs en tiempo real:**
```bash
tail -f logs/chatbot.log
tail -f logs/gateway.log
```

**Ver todos los logs:**
```bash
tail -f logs/*.log
```

---

## üõ†Ô∏è Comandos √ötiles

### Iniciar todos los servicios:
```bash
./start-all.sh
```

### Ver estado de servicios:
```bash
./start-all.sh status
```

### Detener todos los servicios:
```bash
./start-all.sh stop
# O
./stop-all.sh
```

### Reiniciar todos los servicios:
```bash
./start-all.sh restart
```

### Verificar puertos:
```bash
lsof -i :5001  # Chatbot
lsof -i :5002  # Educaci√≥n
lsof -i :5003  # Simulaci√≥n
lsof -i :5004  # Radiograf√≠as
lsof -i :5005  # NV-Reason-CXR
lsof -i :3001  # Gateway
```

---

## üåê URLs de Acceso

### Local (localhost):
- **Gateway:** http://localhost:3001
- **Chatbot:** http://localhost:5001
- **Educaci√≥n:** http://localhost:5002
- **Simulaci√≥n:** http://localhost:5003
- **Radiograf√≠as:** http://localhost:5004
- **NV-Reason-CXR:** http://localhost:5005

### Red Local:
- **Gateway:** http://[LOCAL_IP]:3001
- **Chatbot:** http://[LOCAL_IP]:5001
- **Educaci√≥n:** http://[LOCAL_IP]:5002
- **Simulaci√≥n:** http://[LOCAL_IP]:5003
- **Radiograf√≠as:** http://[LOCAL_IP]:5004
- **NV-Reason-CXR:** http://[LOCAL_IP]:5005

---

## ‚öôÔ∏è Configuraciones Importantes

### Variables de Entorno del Gateway

El gateway necesita conocer las IPs locales de los servicios backend:

```bash
HOSTNAME=0.0.0.0
SERVICIO_CHATBOT_URL=http://[LOCAL_IP]:5001
SERVICIO_EDUCACION_URL=http://[LOCAL_IP]:5002
SERVICIO_SIMULACION_URL=http://[LOCAL_IP]:5003
SERVICIO_RADIOGRAFIAS_URL=http://[LOCAL_IP]:5004
```

### Entorno Virtual (venv)

Todos los servicios Python pueden usar un venv compartido:
- Ruta: `Pruebas-del-IMSS/venv/`
- Si existe, se activa autom√°ticamente
- Si no existe, usa Python del sistema

### Forzar CPU

Algunos servicios usan `FORCE_CPU=1` para evitar problemas de VRAM:
- Radiograf√≠as: `FORCE_CPU=1`
- NV-Reason-CXR: `FORCE_CPU=1`

---

## üîç Troubleshooting

### Problema: Puerto ya en uso
**Soluci√≥n:**
```bash
# El script autom√°ticamente mata procesos en puertos ocupados
# Si persiste, manualmente:
lsof -ti:5001 | xargs kill -9
```

### Problema: Servicio no inicia
**Soluci√≥n:**
1. Verificar logs: `tail -f logs/[servicio].log`
2. Verificar dependencias: `pip list` o `npm list`
3. Verificar Python/Node: `python3 --version`, `node --version`

### Problema: Gateway no conecta con backends
**Soluci√≥n:**
1. Verificar IP local: El script la detecta autom√°ticamente
2. Verificar variables de entorno del gateway
3. Verificar que los backends est√©n escuchando en `0.0.0.0` o IP local

### Problema: NV-Reason-CXR no encuentra modelo
**Soluci√≥n:**
1. Verificar que el modelo est√© en `~/.cache/huggingface/hub/`
2. O definir `NV_REASON_MODEL_PATH`
3. O permitir descargas: `NV_REASON_ALLOW_DOWNLOADS=1`

---

## üìù Notas Importantes

1. **Orden de inicio:** Los backends se inician primero, luego el gateway
2. **Esperas:** Hay esperas estrat√©gicas para que los servicios se inicien
3. **Health checks:** No bloquean el inicio, solo verifican
4. **Monitoreo:** El script se mantiene ejecutando para monitorear servicios
5. **Limpieza:** Al presionar Ctrl+C, limpia todos los procesos autom√°ticamente

---

## üéØ Resumen de Comandos de Inicio

| Servicio | Comando | Puerto | Venv |
|----------|---------|--------|------|
| Chatbot | `cd chatbot && python3 main.py` | 5001 | ‚úÖ |
| Educaci√≥n | `cd Educacion_radiografia && python3 app.py` | 5002 | ‚ùå |
| Simulaci√≥n | `cd Simulacion && python3 app.py` | 5003 | ‚ùå |
| Radiograf√≠as | `cd radiografias_torax/backend && FORCE_CPU=1 python3 app.py` | 5004 | ‚úÖ |
| NV-Reason-CXR | `cd nv-reason-cxr && PORT=5005 FORCE_CPU=1 bash run_local.sh` | 5005 | ‚úÖ |
| Gateway | `cd UI_IMSS && npm run dev` | 3001 | ‚ùå |

---

## ‚úÖ Checklist de Inicio

- [ ] Python 3.x instalado
- [ ] Node.js y npm instalados
- [ ] Dependencias Python instaladas (venv o sistema)
- [ ] Dependencias Node.js instaladas (`npm install` en UI_IMSS)
- [ ] Modelos descargados (si es necesario)
- [ ] Puertos libres (3001, 5001-5005)
- [ ] Permisos de ejecuci√≥n: `chmod +x start-all.sh`
- [ ] Directorio `logs/` existe o se crear√° autom√°ticamente

---

**√öltima actualizaci√≥n:** 2025-11-10
**Versi√≥n del script:** 1.0






