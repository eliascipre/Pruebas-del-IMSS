"""
Sistema de an√°lisis m√©dico para im√°genes - vLLM con Ray Serve
"""

import base64
import logging
import os
import httpx
from typing import Dict, Any, Optional
import json

logger = logging.getLogger(__name__)

# Configuraci√≥n - Prioridad: VLLM_ENDPOINT > OLLAMA_ENDPOINT > LM_STUDIO_ENDPOINT
VLLM_ENDPOINT = os.getenv("VLLM_ENDPOINT", os.getenv("OLLAMA_ENDPOINT", os.getenv("LM_STUDIO_ENDPOINT", "http://localhost:8000/v1/")))
# Asegurar que termine con /v1/ para compatibilidad con OpenAI API
if not VLLM_ENDPOINT.endswith("/v1/"):
    if VLLM_ENDPOINT.endswith("/"):
        VLLM_ENDPOINT = VLLM_ENDPOINT + "v1/"
    else:
        VLLM_ENDPOINT = VLLM_ENDPOINT + "/v1/"
MODEL_NAME = "google/medgemma-27b-it"


class MedicalImageAnalysis:
    """Sistema de an√°lisis de im√°genes m√©dicas con vLLM con Ray Serve"""
    
    def __init__(self):
        logger.info(f"‚úÖ Configurado para usar vLLM con Ray Serve en: {VLLM_ENDPOINT}")
        logger.info(f"‚úÖ Modelo: {MODEL_NAME}")
    
    async def analyze_with_ollama(self, image_data: str, prompt: str) -> Dict[str, Any]:
        """Analizar imagen usando vLLM con Ray Serve con formato multimodal"""
        try:
            logger.info(f"ü§ñ Analizando con vLLM: {MODEL_NAME}")
            
            # Decodificar imagen para obtener metadata
            image_bytes = base64.b64decode(image_data)
            image_size = len(image_bytes)
            
            # Crear el prompt m√©dico mejorado
            system_prompt = """Eres un radi√≥logo asistente especializado del IMSS.
Analiza la imagen m√©dica proporcionada y proporciona:
1. Descripci√≥n de estructuras anat√≥micas visibles
2. Hallazgos normales y anormales
3. Posibles patolog√≠as o alteraciones
4. Recomendaciones profesionales
5. Siempre remitir a consulta m√©dica para confirmaci√≥n

Responde en espa√±ol de manera detallada y profesional."""
            
            # Preparar mensaje multimodal seg√∫n formato LangChain
            user_prompt_text = prompt if prompt else "Analiza esta radiograf√≠a m√©dica en detalle"
            
            # Formato multimodal: content es un array
            multimodal_content = [
                {
                    "type": "text",
                    "text": user_prompt_text
                },
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{image_data}"
                    }
                }
            ]
            
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": multimodal_content}
            ]
            
            logger.info(f"üìè Enviando imagen (tama√±o: {image_size} bytes) con formato multimodal")
            
            async with httpx.AsyncClient(timeout=120.0) as client:
                response = await client.post(
                    f"{VLLM_ENDPOINT}chat/completions",
                    json={
                        "model": MODEL_NAME,
                        "messages": messages,
                        "temperature": 0.7,
                        "max_tokens": 100,
                        "stream": False
                    }
                )
                
                if response.status_code == 200:
                    result = response.json()
                    analysis = result["choices"][0]["message"]["content"]
                    
                    logger.info(f"‚úÖ vLLM response recibida (an√°lisis multimodal)")
                    return {
                        "success": True,
                        "analysis": analysis,
                        "model": MODEL_NAME,
                        "provider": "vllm"
                    }
                else:
                    error_text = response.text
                    logger.error(f"‚ùå Error en vLLM: {response.status_code} - {error_text}")
                    return {
                        "success": False,
                        "error": f"HTTP {response.status_code}: {error_text}",
                        "provider": "vllm"
                    }
        except Exception as e:
            logger.error(f"‚ùå Error en an√°lisis con vLLM: {str(e)}")
            import traceback
            logger.error(f"Traceback: {traceback.format_exc()}")
            return {
                "success": False,
                "error": str(e),
                "provider": "vllm"
            }
    
    async def analyze_with_fallback(self, image_data: str, image_format: str, prompt: str) -> Dict[str, Any]:
        """An√°lisis de imagen con vLLM con Ray Serve"""
        return await self.analyze_with_ollama(image_data, prompt)


# Instancia global
medical_analyzer = MedicalImageAnalysis()


async def analyze_image_with_fallback(image_data: str, image_format: str, prompt: str) -> Dict[str, Any]:
    """Funci√≥n helper para an√°lisis de imagen con vLLM con Ray Serve"""
    return await medical_analyzer.analyze_with_fallback(image_data, image_format, prompt)
