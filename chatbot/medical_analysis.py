"""
Sistema de an√°lisis m√©dico para im√°genes - vLLM con Ray Serve
"""

import base64
import logging
import os
import httpx
from typing import Dict, Any, Optional
import json
from PIL import Image
import io

logger = logging.getLogger(__name__)

# Configuraci√≥n - Prioridad: VLLM_ENDPOINT > OLLAMA_ENDPOINT > LM_STUDIO_ENDPOINT
VLLM_ENDPOINT = os.getenv("VLLM_ENDPOINT", os.getenv("OLLAMA_ENDPOINT", os.getenv("LM_STUDIO_ENDPOINT", "http://localhost:8000/v1/")))
# Asegurar que termine con /v1/ para compatibilidad con OpenAI API
if not VLLM_ENDPOINT.endswith("/v1/"):
    if VLLM_ENDPOINT.endswith("/"):
        VLLM_ENDPOINT = VLLM_ENDPOINT + "v1/"
    else:
        VLLM_ENDPOINT = VLLM_ENDPOINT + "/v1/"
MODEL_NAME = "google/medgemma-27b-it"

# L√≠mites para im√°genes
MAX_IMAGE_SIZE_MB = 2  # 2MB m√°ximo en bytes originales
MAX_IMAGE_DIMENSION = 512  # M√°ximo 512px en cualquier dimensi√≥n
MAX_IMAGE_QUALITY = 85  # Calidad JPEG (0-100)
MAX_IMAGE_TOKENS = 4500  # ~3500 tokens m√°ximo para imagen en base64 (aumentado para permitir im√°genes m√°s grandes)


def compress_image(image_data: str, max_dimension: int = MAX_IMAGE_DIMENSION, quality: int = MAX_IMAGE_QUALITY) -> str:
    """Comprimir imagen a tama√±o m√°ximo y calidad para reducir tokens"""
    try:
        # Decodificar base64
        image_bytes = base64.b64decode(image_data)
        original_size = len(image_bytes)
        
        # Abrir imagen
        image = Image.open(io.BytesIO(image_bytes))
        original_mode = image.mode
        
        # Convertir a RGB si es necesario (JPEG solo soporta RGB)
        if image.mode != 'RGB':
            image = image.convert('RGB')
        
        # Redimensionar si es muy grande
        if max(image.size) > max_dimension:
            image.thumbnail((max_dimension, max_dimension), Image.Resampling.LANCZOS)
            logger.info(f"üìê Imagen redimensionada a {image.size}")
        
        # Comprimir a JPEG
        output = io.BytesIO()
        image.save(output, format='JPEG', quality=quality, optimize=True)
        output.seek(0)
        
        # Codificar a base64
        compressed_base64 = base64.b64encode(output.read()).decode('utf-8')
        compressed_size = len(compressed_base64)
        
        # Calcular reducci√≥n
        reduction = ((original_size - len(base64.b64decode(compressed_base64))) / original_size) * 100 if original_size > 0 else 0
        
        logger.info(f"üì¶ Imagen comprimida: {original_size / 1024:.1f}KB ‚Üí {len(base64.b64decode(compressed_base64)) / 1024:.1f}KB ({reduction:.1f}% reducci√≥n)")
        logger.info(f"üìä Tama√±o base64: {len(image_data)} ‚Üí {compressed_size} caracteres")
        
        return compressed_base64
    except Exception as e:
        logger.error(f"‚ùå Error comprimiendo imagen: {e}")
        # Si falla la compresi√≥n, devolver la imagen original
        return image_data


def validate_image_size(image_data: str) -> tuple[bool, Optional[str]]:
    """Validar que la imagen no exceda el l√≠mite de tokens"""
    try:
        # Decodificar para obtener tama√±o en bytes
        image_bytes = base64.b64decode(image_data)
        size_mb = len(image_bytes) / (1024 * 1024)
        
        # Validar tama√±o en MB
        if size_mb > MAX_IMAGE_SIZE_MB:
            return False, f"Imagen muy grande ({size_mb:.2f}MB). M√°ximo permitido: {MAX_IMAGE_SIZE_MB}MB"
        
        # Estimar tokens (base64 es ~33% m√°s grande que bytes originales)
        # Aproximaci√≥n: 4 caracteres base64 = 1 token
        estimated_tokens = len(image_data) // 4
        
        if estimated_tokens > MAX_IMAGE_TOKENS:
            return False, f"Imagen excede l√≠mite de tokens estimados ({estimated_tokens}). M√°ximo: {MAX_IMAGE_TOKENS} tokens"
        
        logger.info(f"‚úÖ Imagen validada: {size_mb:.2f}MB, ~{estimated_tokens} tokens estimados")
        return True, None
    except Exception as e:
        logger.error(f"‚ùå Error validando imagen: {e}")
        return False, f"Error validando imagen: {str(e)}"


class MedicalImageAnalysis:
    """Sistema de an√°lisis de im√°genes m√©dicas con vLLM con Ray Serve"""
    
    def __init__(self):
        logger.info(f"‚úÖ Configurado para usar vLLM con Ray Serve en: {VLLM_ENDPOINT}")
        logger.info(f"‚úÖ Modelo: {MODEL_NAME}")
    
    async def analyze_with_ollama(self, image_data: str, prompt: str) -> Dict[str, Any]:
        """Analizar imagen usando vLLM con Ray Serve con formato multimodal"""
        try:
            logger.info(f"ü§ñ Analizando con vLLM: {MODEL_NAME}")
            
            # Validar tama√±o de imagen
            is_valid, error_msg = validate_image_size(image_data)
            if not is_valid:
                logger.warning(f"‚ö†Ô∏è {error_msg}. Comprimiendo imagen...")
                # Comprimir imagen si es muy grande
                image_data = compress_image(image_data)
                # Validar nuevamente despu√©s de compresi√≥n
                is_valid, error_msg = validate_image_size(image_data)
                if not is_valid:
                    return {
                        "success": False,
                        "error": f"Imagen demasiado grande incluso despu√©s de compresi√≥n: {error_msg}",
                        "provider": "vllm"
                    }
            
            # Decodificar imagen para obtener metadata
            image_bytes = base64.b64decode(image_data)
            image_size = len(image_bytes)
            
            # Crear el prompt m√©dico mejorado
            system_prompt = """Eres un radi√≥logo asistente especializado del IMSS.
Analiza la imagen m√©dica proporcionada y proporciona:
1. Descripci√≥n de estructuras anat√≥micas visibles
2. Hallazgos normales y anormales
3. Posibles patolog√≠as o alteraciones
4. Recomendaciones profesionales
5. Siempre remitir a consulta m√©dica para confirmaci√≥n

Responde en espa√±ol de manera detallada y profesional."""
            
            # Preparar mensaje multimodal seg√∫n formato LangChain
            user_prompt_text = prompt if prompt else "Analiza esta radiograf√≠a m√©dica en detalle"
            
            # Formato multimodal: content es un array
            multimodal_content = [
                {
                    "type": "text",
                    "text": user_prompt_text
                },
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{image_data}"
                    }
                }
            ]
            
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": multimodal_content}
            ]
            
            logger.info(f"üìè Enviando imagen (tama√±o: {image_size} bytes) con formato multimodal")
            
            async with httpx.AsyncClient(timeout=120.0) as client:
                response = await client.post(
                    f"{VLLM_ENDPOINT}chat/completions",
                    json={
                        "model": MODEL_NAME,
                        "messages": messages,
                        "temperature": 0.7,
                        "max_tokens": 2048,  # Aumentado de 100 a 2048 para respuestas m√°s completas
                        "stream": False
                    }
                )
                
                if response.status_code == 200:
                    result = response.json()
                    analysis = result["choices"][0]["message"]["content"]
                    
                    # Logging detallado de la respuesta
                    logger.info(f"‚úÖ vLLM response recibida (an√°lisis multimodal)")
                    logger.info(f"üìù Respuesta del modelo (primeros 200 caracteres): {analysis[:200]}...")
                    logger.info(f"üìä Tama√±o de la respuesta: {len(analysis)} caracteres")
                    
                    # Verificar si la respuesta parece ser un an√°lisis real o solo texto gen√©rico
                    if len(analysis) < 50:
                        logger.warning(f"‚ö†Ô∏è Respuesta muy corta ({len(analysis)} caracteres). El modelo puede no estar procesando la imagen correctamente.")
                    
                    return {
                        "success": True,
                        "analysis": analysis,
                        "model": MODEL_NAME,
                        "provider": "vllm"
                    }
                else:
                    error_text = response.text[:2000]  # Limitar tama√±o del error
                    logger.error(f"‚ùå Error en vLLM: {response.status_code}")
                    logger.error(f"üìã Detalles del error: {error_text}")
                    
                    # Intentar parsear error si es JSON
                    try:
                        error_json = json.loads(error_text)
                        error_detail = error_json.get('error', {}).get('message', error_text) if isinstance(error_json.get('error'), dict) else error_text
                    except:
                        error_detail = error_text
                    
                    return {
                        "success": False,
                        "error": f"Error del servidor ({response.status_code}): {error_detail[:500]}",
                        "provider": "vllm"
                    }
        except Exception as e:
            logger.error(f"‚ùå Error en an√°lisis con vLLM: {str(e)}")
            import traceback
            logger.error(f"Traceback: {traceback.format_exc()}")
            return {
                "success": False,
                "error": str(e),
                "provider": "vllm"
            }
    
    async def analyze_with_fallback(self, image_data: str, image_format: str, prompt: str) -> Dict[str, Any]:
        """An√°lisis de imagen con vLLM con Ray Serve"""
        return await self.analyze_with_ollama(image_data, prompt)


# Instancia global
medical_analyzer = MedicalImageAnalysis()


async def analyze_image_with_fallback(image_data: str, image_format: str, prompt: str) -> Dict[str, Any]:
    """Funci√≥n helper para an√°lisis de imagen con vLLM con Ray Serve"""
    return await medical_analyzer.analyze_with_fallback(image_data, image_format, prompt)
