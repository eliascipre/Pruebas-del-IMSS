# An√°lisis de Rendimiento y Optimizaci√≥n para 160 peticiones/minuto

## üìä An√°lisis Actual del Sistema

### Backend (FastAPI)

#### Problemas Identificados:

1. **SQLite sin Pool de Conexiones** ‚ö†Ô∏è CR√çTICO
   - `auth_manager.py`: Usa `sqlite3.connect()` s√≠ncrono en cada petici√≥n
   - `memory_manager.py`: M√∫ltiples conexiones s√≠ncronas bloqueantes
   - SQLite no soporta m√∫ltiples escrituras concurrentes eficientemente
   - **Impacto**: Bloquea el event loop de asyncio

2. **Uvicorn sin Workers** ‚ö†Ô∏è ALTO
   - Solo 1 worker por defecto
   - No aprovecha m√∫ltiples cores
   - **Impacto**: Limita concurrencia a ~50-100 peticiones/segundo

3. **httpx sin Connection Pooling** ‚ö†Ô∏è MEDIO
   - Cada petici√≥n a vLLM crea nueva conexi√≥n
   - Overhead de TCP handshake
   - **Impacto**: Latencia adicional de 10-50ms por petici√≥n

4. **Sin Rate Limiting** ‚ö†Ô∏è MEDIO
   - No hay protecci√≥n contra abuso
   - Un usuario puede saturar el sistema

5. **Verificaci√≥n de Token en cada petici√≥n** ‚ö†Ô∏è MEDIO
   - `ProtectedRoute` hace petici√≥n HTTP al backend
   - No hay caching de tokens v√°lidos
   - **Impacto**: Latencia adicional de 50-100ms

### Frontend (Next.js)

#### Problemas Identificados:

1. **ProtectedRoute sin Caching** ‚ö†Ô∏è MEDIO
   - Verifica token en cada navegaci√≥n
   - No cachea resultado de verificaci√≥n

2. **M√∫ltiples Fetch sin Debouncing** ‚ö†Ô∏è BAJO
   - `fetchConversations` se llama m√∫ltiples veces
   - No hay debouncing en b√∫squedas

## üöÄ Estrategias de Optimizaci√≥n

### 1. Migrar SQLite a Pool As√≠ncrono (CR√çTICO)

**Problema**: SQLite bloquea el event loop
**Soluci√≥n**: Usar `aiosqlite` o `databases` con SQLite

```python
# Usar aiosqlite para operaciones as√≠ncronas
import aiosqlite

class AsyncAuthManager:
    def __init__(self, db_path: str = "chatbot.db"):
        self.db_path = db_path
        self.pool = None
    
    async def get_connection(self):
        if not self.pool:
            self.pool = await aiosqlite.connect(self.db_path)
        return self.pool
```

### 2. Configurar Uvicorn con Workers (ALTO)

**Problema**: Solo 1 worker
**Soluci√≥n**: Usar m√∫ltiples workers

```bash
# run.sh optimizado
uvicorn main:app \
    --host 0.0.0.0 \
    --port 5001 \
    --workers 4 \
    --worker-class uvicorn.workers.UvicornWorker \
    --limit-concurrency 200 \
    --timeout-keep-alive 30
```

### 3. Connection Pooling para httpx (MEDIO)

**Problema**: Nueva conexi√≥n por petici√≥n
**Soluci√≥n**: Pool de conexiones reutilizable

```python
import httpx

class HTTPXPool:
    def __init__(self):
        self.client = httpx.AsyncClient(
            limits=httpx.Limits(
                max_keepalive_connections=20,
                max_connections=100,
                keepalive_expiry=30.0
            ),
            timeout=httpx.Timeout(120.0)
        )
```

### 4. Caching de Tokens (MEDIO)

**Problema**: Verificaci√≥n en cada petici√≥n
**Soluci√≥n**: Cache en memoria con TTL

```python
from functools import lru_cache
from datetime import datetime, timedelta

class TokenCache:
    def __init__(self):
        self.cache = {}
        self.ttl = timedelta(minutes=5)
    
    def get(self, token: str):
        if token in self.cache:
            user, expiry = self.cache[token]
            if datetime.now() < expiry:
                return user
            del self.cache[token]
        return None
    
    def set(self, token: str, user: dict):
        self.cache[token] = (user, datetime.now() + self.ttl)
```

### 5. Rate Limiting (MEDIO)

**Problema**: Sin protecci√≥n contra abuso
**Soluci√≥n**: Implementar rate limiting

```python
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

@app.post("/api/chat")
@limiter.limit("10/minute")  # 10 peticiones por minuto por IP
async def chat_endpoint(...):
    ...
```

### 6. Optimizar Frontend (BAJO)

**Problema**: Verificaci√≥n de token en cada carga
**Soluci√≥n**: Cache en localStorage con validaci√≥n peri√≥dica

```typescript
// Cache de verificaci√≥n de token
const TOKEN_CACHE_KEY = 'token_verified'
const TOKEN_CACHE_TTL = 5 * 60 * 1000 // 5 minutos

function isTokenCached(): boolean {
  const cached = localStorage.getItem(TOKEN_CACHE_KEY)
  if (!cached) return false
  
  const { timestamp } = JSON.parse(cached)
  return Date.now() - timestamp < TOKEN_CACHE_TTL
}
```

## üìà Estimaci√≥n de Capacidad

### Configuraci√≥n Actual:
- **Workers**: 1
- **Concurrencia**: ~50-100 peticiones/segundo
- **SQLite**: Bloqueante
- **Capacidad estimada**: ~30-60 peticiones/minuto

### Configuraci√≥n Optimizada:
- **Workers**: 4
- **Concurrencia**: ~200-400 peticiones/segundo
- **SQLite**: As√≠ncrono con pool
- **Connection Pooling**: httpx reutilizable
- **Capacidad estimada**: **200-300 peticiones/minuto** ‚úÖ

## üéØ Plan de Implementaci√≥n

1. **Fase 1 (Cr√≠tico)**: Migrar a aiosqlite
2. **Fase 2 (Alto)**: Configurar workers de Uvicorn
3. **Fase 3 (Medio)**: Connection pooling httpx
4. **Fase 4 (Medio)**: Caching de tokens
5. **Fase 5 (Medio)**: Rate limiting
6. **Fase 6 (Bajo)**: Optimizaciones frontend




