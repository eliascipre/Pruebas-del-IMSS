# Instalaci√≥n de Whisper large-v3-turbo

## Cambios Implementados

Se ha actualizado el servicio de transcripci√≥n para usar **Hugging Face Transformers** en lugar de `openai-whisper`, siguiendo la documentaci√≥n oficial de [Whisper large-v3-turbo](https://huggingface.co/openai/whisper-large-v3-turbo).

## Instalaci√≥n

### 1. Instalar Dependencias

```bash
cd chatbot
pip install -r requirements.txt
```

O instalar manualmente:

```bash
pip install --upgrade transformers datasets[audio] accelerate torch torchaudio
```

### 2. Descargar el Modelo

El modelo se descargar√° autom√°ticamente la primera vez que se use. Se guardar√° en:
```
chatbot/models/whisper-large-v3-turbo/
```

**Nota**: El modelo pesa aproximadamente 1.5GB, as√≠ que la primera descarga puede tardar unos minutos.

### 3. Verificar Instalaci√≥n

El modelo se cargar√° autom√°ticamente cuando se haga la primera transcripci√≥n. Ver√°s en los logs:

```
INFO:transcription_service:üì• Cargando modelo Whisper 'openai/whisper-large-v3-turbo' (CPU)...
INFO:transcription_service:üì• Descargando modelo a: /ruta/a/chatbot/models/whisper-large-v3-turbo
INFO:transcription_service:‚úÖ Modelo Whisper cargado en cpu
```

## Caracter√≠sticas

- ‚úÖ **Modelo**: `whisper-large-v3-turbo` (optimizado para velocidad)
- ‚úÖ **Ejecuci√≥n**: CPU (torch.float32)
- ‚úÖ **Cache local**: El modelo se guarda en `chatbot/models/whisper-large-v3-turbo/`
- ‚úÖ **Auto-detecci√≥n de idioma**: Detecta autom√°ticamente el idioma del audio
- ‚úÖ **Optimizaciones**: Usa `low_cpu_mem_usage=True` y `use_safetensors=True`

## Uso

El endpoint `/api/transcribe` est√° disponible y requiere autenticaci√≥n:

```python
POST /api/transcribe
{
    "audio_data": "base64_encoded_audio",
    "audio_format": "webm",
    "language": "es"  # opcional
}
```

## Configuraci√≥n Avanzada

### Cambiar el Modelo

Para usar un modelo diferente, edita `chatbot/transcription_service.py`:

```python
_model_id = "openai/whisper-base"  # Modelo m√°s peque√±o y r√°pido
# o
_model_id = "openai/whisper-large-v3"  # Modelo m√°s grande y preciso
```

### Usar GPU (si est√° disponible)

Para usar GPU, modifica `get_whisper_pipeline()`:

```python
device = "cuda:0" if torch.cuda.is_available() else "cpu"
torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32
```

## Soluci√≥n de Problemas

### Error: "No module named 'transformers'"

```bash
pip install transformers>=4.40.0
```

### Error: "No module named 'torch'"

```bash
pip install torch>=2.0.0 torchaudio>=2.0.0
```

### El modelo no se descarga

Verifica que tienes conexi√≥n a internet y espacio en disco (al menos 2GB libres).

### Error de memoria

Si tienes problemas de memoria, usa un modelo m√°s peque√±o:

```python
_model_id = "openai/whisper-base"  # ~150MB
```

## Referencias

- [Documentaci√≥n oficial de Whisper large-v3-turbo](https://huggingface.co/openai/whisper-large-v3-turbo)
- [Hugging Face Transformers](https://huggingface.co/docs/transformers)





